{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCZG4zLUsFZ9/cCC4gd/wW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jared-ni/6.8610-project/blob/main/claude_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install spacy\n",
        "!pip install scispacy\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install deep-translator\n",
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlKj99ZdKsNH",
        "outputId": "5cf95835-38c0-4a6c-f125-8dfceccbf0b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting scispacy\n",
            "  Downloading scispacy-0.5.5-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from scispacy) (3.7.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.13.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scispacy) (2.32.3)\n",
            "Collecting conllu (from scispacy)\n",
            "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.26.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from scispacy) (1.5.2)\n",
            "Collecting pysbd (from scispacy)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting nmslib>=1.7.3.6 (from scispacy)\n",
            "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11<2.6.2 (from nmslib>=1.7.3.6->scispacy)\n",
            "  Using cached pybind11-2.6.1-py2.py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nmslib>=1.7.3.6->scispacy) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.3->scispacy) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.15.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (4.66.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (4.12.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->scispacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (0.1.2)\n",
            "Downloading scispacy-0.5.5-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
            "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "Building wheels for collected packages: nmslib\n",
            "  Building wheel for nmslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13578643 sha256=fb3327a133abdc7c2045069e93059954ad8653b61e04f5be3078f760ece85121\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
            "Successfully built nmslib\n",
            "Installing collected packages: pysbd, pybind11, conllu, nmslib, scispacy\n",
            "Successfully installed conllu-6.0.0 nmslib-2.1.1 pybind11-2.6.1 pysbd-0.3.4 scispacy-0.5.5\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz\n",
            "  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from en_core_sci_sm==0.5.4) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.15.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.1.2)\n",
            "Building wheels for collected packages: en_core_sci_sm\n",
            "  Building wheel for en_core_sci_sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_core_sci_sm: filename=en_core_sci_sm-0.5.4-py3-none-any.whl size=14778487 sha256=b301d417061d70924f6ee09f5740a7f819335f56ed7bfbf8eea45f7da23ce804\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/d3/6e/e03165bcf8c0fe90c7a41e8a44dd268e4c7779582c5e022707\n",
            "Successfully built en_core_sci_sm\n",
            "Installing collected packages: en_core_sci_sm\n",
            "Successfully installed en_core_sci_sm-0.5.4\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.8.30)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.12.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2024.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=61d42f73ad60f9812f25386933c57033b5e968b8784f0777d8f55e312635a40a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.0\n",
            "    Uninstalling httpx-0.28.0:\n",
            "      Successfully uninstalled httpx-0.28.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langsmith 0.1.147 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "openai 1.54.5 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G32SWSDCJlYW",
        "outputId": "b85ccc4d-2604-48d3-9e23-b0887953cff2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'Name': ['John', 'Mary'], 'Age': [25, 30]})\n",
        "\n",
        "# Write to CSV\n",
        "df.to_csv('/content/drive/My Drive/dummy_data.csv', index=False)"
      ],
      "metadata": {
        "id": "cwfqllz_Jze4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "claude_token = userdata.get('claude_token')"
      ],
      "metadata": {
        "id": "5V2AEAroKh_W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from deep_translator import GoogleTranslator\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "1IGO9IO8LC8o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flags for which LLMs to use\n",
        "USE_LLAMA = True\n",
        "USE_MISTRAL = False\n",
        "USE_FALCON = False\n",
        "\n",
        "# Define max_length multiplier for LLM prompts\n",
        "MAX_LENGTH_MULTIPLIER = 2\n",
        "\n",
        "# Define k hyperparameter\n",
        "K_HYPERPARAMETER = 3"
      ],
      "metadata": {
        "id": "wzFG2dgFLFLs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets into pandas DataFrames\n",
        "def load_law_dataset():\n",
        "    ds = load_dataset(\"casehold/casehold\", \"all\")\n",
        "    train_df = pd.DataFrame(ds['train'])\n",
        "    test_df = pd.DataFrame(ds['test'])\n",
        "    validation_df = pd.DataFrame(ds['validation'])\n",
        "    law_dataset = pd.concat([train_df, test_df, validation_df], ignore_index=True)['citing_prompt']\n",
        "    return law_dataset\n",
        "\n",
        "def load_medical_dataset():\n",
        "    ds = load_dataset(\"zhengyun21/PMC-Patients\")\n",
        "    train_df = pd.DataFrame(ds['train'])\n",
        "    medical_dataset = train_df['patient']\n",
        "    return medical_dataset\n",
        "\n",
        "# Combine datasets\n",
        "def load_all_datasets():\n",
        "    law_dataset = load_law_dataset()\n",
        "    medical_dataset = load_medical_dataset()\n",
        "    return [law_dataset, medical_dataset]"
      ],
      "metadata": {
        "id": "6gn6ZT1kLJac"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SpaCy model\n",
        "def load_spacy_model(model_path='en_core_sci_sm'):\n",
        "    return spacy.load(model_path)\n",
        "\n",
        "# Extract entities from text\n",
        "def extract_entities(nlp, text):\n",
        "    doc = nlp(text)\n",
        "    return [ent.text for ent in doc.ents]\n",
        "\n",
        "# Translate entities to a target language\n",
        "def translate_entities(entities, target_lang):\n",
        "    translations = [GoogleTranslator(source='auto', target=target_lang).translate(entity) for entity in entities]\n",
        "    return translations"
      ],
      "metadata": {
        "id": "CwBGBtSdLLHk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_JTC(translations, text, entities):\n",
        "    jtc_score = 0\n",
        "    n = len(entities)\n",
        "    entity_counts = 0\n",
        "\n",
        "    for entity, translated_entity in entities.items():\n",
        "        # Count occurrences of the entity in the original text\n",
        "        c = text.count(entity)\n",
        "        entity_counts += c\n",
        "        if c == 0 or not translated_entity:\n",
        "            continue  # Skip entities that are not present or have no translation\n",
        "        jargon_inconsistency = K_HYPERPARAMETER * c\n",
        "\n",
        "        for translation in translations:\n",
        "            # Count occurrences of the translated entity in the translation\n",
        "            t = translation.count(translated_entity)\n",
        "            # Calculate penalty for mismatched occurrences\n",
        "            jargon_inconsistency -= t\n",
        "\n",
        "        # Update the JTC score\n",
        "        jtc_score += jargon_inconsistency\n",
        "\n",
        "    # Normalize and invert the score\n",
        "    normalized_score = jtc_score / max(K_HYPERPARAMETER * entity_counts, 1)\n",
        "    return 1 - normalized_score"
      ],
      "metadata": {
        "id": "s0ppkxB3LNJz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA3-UGZ6MPie",
        "outputId": "f8ed55a8-09f5-48dd-bd8a-50803e125cd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.40.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.9.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (2.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.1)\n",
            "Downloading anthropic-0.40.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, anthropic\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.9.0\n",
            "    Uninstalling h11-0.9.0:\n",
            "      Successfully uninstalled h11-0.9.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 0.9.1\n",
            "    Uninstalling httpcore-0.9.1:\n",
            "      Successfully uninstalled httpcore-0.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.13.3\n",
            "    Uninstalling httpx-0.13.3:\n",
            "      Successfully uninstalled httpx-0.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "googletrans 4.0.0rc1 requires httpx==0.13.3, but you have httpx 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.40.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import anthropic\n",
        "\n",
        "# api_key = userdata.get('claude_token')\n",
        "# client = anthropic.Anthropic(api_key=api_key)\n",
        "\n",
        "# message = client.messages.create(\n",
        "#     # model=\"claude-3-5-sonnet-20241022\",\n",
        "#     model=\"claude-3-haiku-20240307\",\n",
        "#     max_tokens=512,\n",
        "#     messages=[\n",
        "#         {\"role\": \"user\", \"content\": \"Please translate this to Chinese: The patient was diagnosed with diabetes and is very sick\"}\n",
        "#     ]\n",
        "# )\n",
        "# print(message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAt5fjyxMFh6",
        "outputId": "975d8720-0c7c-49ea-a18a-8ecc0c590ccc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TextBlock(text='该患者被诊断患有糖尿病,病情非常严重。', type='text')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "# Helper function to interact with Claude\n",
        "def invoke_claude(prompt, model=\"claude-3-haiku-20240307\", max_tokens=512):\n",
        "    api_key = userdata.get('claude_token')\n",
        "    client = anthropic.Anthropic(api_key=api_key)\n",
        "    response = client.messages.create(\n",
        "        model=model,\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.content[0].text"
      ],
      "metadata": {
        "id": "8UBLzQQhSZMS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function for the experiment\n",
        "def run_pipeline_claude(target_lang, results_file_in_drive):\n",
        "    datasets = load_all_datasets()\n",
        "    lang_abbrs = {\"Simplified Chinese\": \"zh-CN\", \"French\": \"fr\"}\n",
        "\n",
        "    # Path to the results file in Google Drive\n",
        "    results_path = f'/content/drive/My Drive/{results_file_in_drive}'\n",
        "\n",
        "    # Initialize the CSV file with headers\n",
        "    with open(results_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Dataset\", \"Text Index\", \"Regular_JTC_Score\", \"LEAP_JTC_Score\"])\n",
        "\n",
        "    for dataset_index, dataset in enumerate(datasets):\n",
        "        dataset_name = \"law\" if dataset_index == 0 else \"medical\"\n",
        "        print(f\"Processing dataset: {dataset_name}\")\n",
        "\n",
        "        for i, text in enumerate(dataset[:10]):\n",
        "            text = \" \".join(text.split()[:50])  # Truncate to the first 50 words\n",
        "            print(f\"Text {i+1}: {text}\")\n",
        "            named_entities = list(set(extract_entities(load_spacy_model(), text)))\n",
        "            print(\"Named entities:\", named_entities)\n",
        "            named_entities_translations = translate_entities(named_entities, lang_abbrs[target_lang])\n",
        "            print(\"Translations:\", named_entities_translations)\n",
        "            named_entity_mapping = {e: t for e, t in zip(named_entities, named_entities_translations)}\n",
        "\n",
        "            # Regular text translation\n",
        "            regular_translations = []\n",
        "            for k in range(3):\n",
        "                prompt = f\"Please return only the answer and nothing else. Translate the following text to {target_lang}: {text}\"\n",
        "                response = invoke_claude(prompt)\n",
        "                print(\"\\nGenerated Response:\", response)\n",
        "                regular_translations.append(response)\n",
        "\n",
        "            # LEAP text translation\n",
        "            leap_translations = []\n",
        "            for k in range(3):\n",
        "                prompt = f\"Please return only the answer and nothing else. Translate the following text to {target_lang} using these mappings {str(named_entities_translations)}: {text}\"\n",
        "                response = invoke_claude(prompt)\n",
        "                print(\"\\nGenerated Response (LEAP):\", response)\n",
        "                leap_translations.append(response)\n",
        "\n",
        "            # Calculate JTC scores\n",
        "            regular_jtc_score = calculate_JTC(regular_translations, text, named_entity_mapping)\n",
        "            leap_jtc_score = calculate_JTC(leap_translations, text, named_entity_mapping)\n",
        "\n",
        "            # Append result to the file in Google Drive\n",
        "            with open(results_path, mode='a', newline='', encoding='utf-8') as file:\n",
        "                writer = csv.writer(file)\n",
        "                row = [dataset_name, i + 1, regular_jtc_score, leap_jtc_score]\n",
        "                writer.writerow(row)\n",
        "                print(f\"Appended result to Google Drive file: {row}\")"
      ],
      "metadata": {
        "id": "dxMashElScQk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline_claude(\"Simplified Chinese\", \"new_claude_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7rTDKY4TK7m",
        "outputId": "c2abf610-7e8b-4ca5-e4da-1819299cce8d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dataset: law\n",
            "Text 1: Drapeau’s cohorts, the cohort would be a “victim” of making the bomb. Further, firebombs are inherently dangerous. There is no peaceful purpose for making a bomb. Felony offenses that involve explosives qualify as “violent crimes” for purposes of enhancing the sentences of career offenders. See 18 U.S.C. § 924(e)(2)(B)(ii) (defining\n",
            "Named entities: ['U.S.C.', 'sentences', 'cohort', 'Drapeau’s cohorts', 'career', 'enhancing', 'offenders', '§', 'Felony', 'victim', 'violent crimes', 'bomb', 'firebombs']\n",
            "Translations: ['美国加州大学', '句子', '同侪', '德拉波的同伙', '职业', '增强', '罪犯', None, '重罪', '受害者', '暴力犯罪', '炸弹', '燃烧弹']\n",
            "\n",
            "Generated Response: 德拉波的同伙,该同伙将成为制造炸弹的\"受害者\"。此外,燃烧弹本质上是危险的。制造炸弹没有和平目的。涉及爆炸物的重罪构成\"暴力犯罪\",以加重惯犯的量刑。见18 U.S.C. § 924(e)(2)(B)(ii) (定义)。\n",
            "\n",
            "Generated Response: 德拉波的同伙,这个同伙就会成为制造炸弹的\"受害者\"。此外,燃料弹也是固有的危险。制造炸弹没有和平目的。涉及爆炸物的重罪犯罪行为被视为\"暴力犯罪\",可以加重惯犯的刑期。\n",
            "\n",
            "Generated Response: 德拉波的同伙,这个同伙会成为制造炸弹的\"受害者\"。此外,燃烧弹本质上是危险的。制造炸弹没有和平用途。涉及爆炸物的重罪构成\"暴力犯罪\",可以加重惯犯的刑期。参见18 U.S.C. § 924(e)(2)(B)(ii)。\n",
            "\n",
            "Generated Response (LEAP): ['美国加州大学', '句子', '同侪', '德拉波的同伙', '职业', '增强', '罪犯', '无', '重罪', '受害者', '暴力犯罪', '炸弹', '燃烧弹']\n",
            "\n",
            "Generated Response (LEAP): 德拉波的同伙、同侪是制造炸弹的\"受害者\"。此外,燃烧弹本质上是很危险的。制造炸弹没有和平目的。涉及爆炸物的重罪属于 \"暴力犯罪\"，可以加重职业罪犯的刑期。见 18 U.S.C. § 924(e)(2)(B)(ii) (定义)。\n",
            "\n",
            "Generated Response (LEAP): 德拉波的同伙, 同侪会成为制造炸弹的\"受害者\"。此外, 燃烧弹本质上是危险的。制造炸弹没有和平目的。涉及爆炸物的重罪行为被视为\"暴力犯罪\",会加重职业罪犯的刑罚。参见 18 美国法典第 924(e)(2)(B)(ii) 条(定义)。\n",
            "Appended result to Google Drive file: ['law', 1, 0.5, 0.7291666666666667]\n",
            "Text 2: Colameta used customer information that he took from Protégé. Additionally, Colameta admits to having taken at least two Protégé proposals with him to Monument. This type of information may constitute trade secrets. See G.L.c. 266, §30 (defining “trade secret” as used in G.L.c. 93, §42, as including “anything tangible or\n",
            "Named entities: ['Colameta admits', 'G.L.c', 'anything', 'Protégé', 'Colameta', 'Protégé proposals', 'information', '§', 'tangible', 'trade', 'secrets', 'customer', 'Monument']\n",
            "Translations: ['Colameta 承认', '財政署', '任何事物', '受保护者', '科拉梅塔', '受保护的提案', '信息', None, '有形', '贸易', '秘密', '顾客', '纪念碑']\n",
            "\n",
            "Generated Response: 科拉-米塔使用了从普罗泰格取得的客户信息。此外,科拉-米塔承认至少带走了两份普罗泰格的提案,前往蒙努门特。这类信息可能构成商业秘密。参见普通法第266章第30条(将\"商业秘密\"定义为普通法第93章第42条所涵盖的\"任何有形或无形的东西\")。\n",
            "\n",
            "Generated Response: Colameta使用了他从Protégé获取的客户信息。此外,Colameta承认至少带走了两份Protégé的提案到Monument。这类信息可能构成商业机密。参见《普通法典》第266条第30款(将\"商业机密\"定义为《普通法典》第93条第42款中使用的\"任何有形或无形的东西\")。\n",
            "\n",
            "Generated Response: 科拉梅塔使用了他从普罗泰格获取的客户信息。此外,科拉梅塔承认将至少两份普罗泰格的提案带到纪念碑公司。这类信息可能构成商业机密。参见普通法第266章第30节(在普通法第93章第42节中定义\"商业机密\"包括\"任何有形或无形的东西\")。\n",
            "\n",
            "Generated Response (LEAP): 科拉梅塔 承认, 從受保护者那里获取了顾客信息。此外, 科拉梅塔承认带走了至少两个受保护的提案到纪念碑。这种信息可能构成商业秘密。参见G.L.c. 266, §30 (定义 \"商业秘密\"用于G.L.c. 93, §42, 包括 \"任何有形或无形的事物\")。\n",
            "\n",
            "Generated Response (LEAP): 科拉梅塔 承认 使用了 从 受保护者 那里取得的 顾客 信息。此外, 科拉梅塔 承认 带走了 至少两个 受保护的提案 到 纪念碑。这类 信息 可能构成 贸易 秘密。见 G.L.c. 266, §30 (将 \"贸易秘密\" 定义为 G.L.c. 93, §42 中所使用的 \"任何事物 有形 或\n",
            "\n",
            "Generated Response (LEAP): 科拉梅塔 承认, 他从 受保护者 那里获取了顾客信息。此外, 科拉梅塔承认他至少带走了两个 受保护的提案 去了 纪念碑。这种信息可能构成 秘密。参见 G.L.c. 266, §30 (G.L.c. 93, §42中定义的\"商业秘密\"包括\"任何有形或无形的事物\")。\n",
            "Appended result to Google Drive file: ['law', 2, 0.3508771929824561, 0.736842105263158]\n",
            "Text 3: property tax sale. In reviewing section 6323(b)(6), this Court noted that it provides that a county’s tax lien has priority over a federal lien, and thus, Taylor purchased the property still subject to the county’s lien. Taylor v. Mill, 310 S.C. 526, 528, 426 S.E.2d 311, 312 (1992). Thus, this\n",
            "Named entities: ['S.E.2d', 'property tax', 'reviewing section 6323(b)(6', 'sale', 'Taylor v. Mill', 'county’s tax', 'Taylor', 'lien', 'county’s lien', 'federal lien', 'property', 'priority']\n",
            "Translations: ['东南2d', '财产税', '审查第 6323(b)(6) 条', '销售', '泰勒诉密尔', '县税', '泰勒', '留置权', '县留置权', '联邦留置权', '财产', '优先事项']\n",
            "\n",
            "Generated Response: 财产税出售\n",
            "\n",
            "Generated Response: 房地产税拍卖\n",
            "\n",
            "Generated Response: 财产税拍卖\n",
            "\n",
            "Generated Response (LEAP): 财产税销售。在审查第 6323(b)(6)条时,法院指出它规定县级税收留置权优先于联邦留置权,因此泰勒仍然购买了受制于县级留置权的财产。泰勒诉密尔，310 S.C. 526, 528, 426 S.E.2d 311, 312 (1992)。因此,\n",
            "\n",
            "Generated Response (LEAP): 财产税销售。在审查第 6323(b)(6)条时,本法院注意到它规定了县政府的税收留置权优先于联邦留置权,因此泰勒仍受县政府留置权的约束购买了该物业。泰勒诉密尔，310 S.C. 526, 528, 426 S.E.2d 311, 312 (1992)。因此,\n",
            "\n",
            "Generated Response (LEAP): 财产税销售。在审查第 6323(b)(6)条时,本法院注意到它规定县级税收留置权优先于联邦留置权,因此泰勒购买的财产仍受制于县级留置权。泰勒诉密尔，310 S.C. 526, 528, 426 S.E.2d 311, 312 (1992)。因此,这\n",
            "Appended result to Google Drive file: ['law', 3, 0.08333333333333337, 0.6666666666666667]\n",
            "Text 4: They also rely on Oswego Laborers’ Local 214 Pension Fund v. Marine Midland Bank, 85 N.Y.2d 20, 623 N.Y.S.2d 529, 647 N.E.2d 741 (1995), which held that a plaintiff “must demonstrate that the acts or practices have a broader impact on consumers at large.” Defs.’ Mem. at 14 (quoting Oswego\n",
            "Named entities: ['consumers', 'N.Y.S.2d 529', 'Pension', 'Defs', 'impact', 'Fund v. Marine Midland Bank', 'Oswego Laborers’ Local 214', 'Oswego', 'plaintiff', 'practices']\n",
            "Translations: ['消费者', '纽约州第二区 529', '养老金', '定义', '影响', '基金诉 Marine Midland Bank', '奥斯威戈劳工地方工会 214', '奥斯特戈', '原告', '实践']\n",
            "\n",
            "Generated Response: 他们也依赖于奥斯威戈工人联合会第214号养老基金诉玛丽恩米德兰银行,85 N.Y.2d 20, 623 N.Y.S.2d 529, 647 N.E.2d 741 (1995)一案,该案认为,原告\"必须证明行为或做法对广大消费者产生了更广泛的影响\"。被告备忘录第14页引用奥斯威戈一案。\n",
            "\n",
            "Generated Response: 他们还依赖于奥斯威戈工人地方214退休基金诉海事中城银行案,85 N.Y.2d 20, 623 N.Y.S.2d 529, 647 N.E.2d 741 (1995)，该案判决原告\"必须证明该行为或做法对广大消费者产生更广泛的影响\"。被告备忘录第14页(引用奥斯威戈案)。\n",
            "\n",
            "Generated Response: 他们还依赖于奥斯威戈劳工联盟 214 号退休金基金诉海军中间银行一案,该案于1995年做出判决,判决指出原告\"必须证明该行为或做法对广大消费者产生更广泛的影响\"。\n",
            "\n",
            "Generated Response (LEAP): 他们也依赖于奥斯威戈劳工地方工会 214 养老金基金诉 Marine Midland Bank 一案,该案于 1995 年做出判决,认为原告\"必须证明该行为或实践对广大消费者有更广泛的影响。\"被告备忘录第 14 页引述。\n",
            "\n",
            "Generated Response (LEAP): 消费者必须证明行为或做法对消费者群体产生较广泛的影响。\n",
            "\n",
            "Generated Response (LEAP): 他们还依赖于奥斯威戈劳工地方工会 214 养老金诉 Marine Midland Bank 案,该案于1995年在纽约州第二区 529 中判决,原告\"必须证明该行为或实践对广大消费者产生更广泛的影响。\"\n",
            "Appended result to Google Drive file: ['law', 4, 0.2727272727272727, 0.5151515151515151]\n",
            "Text 5: did not affect the defendant’s guideline range, a sentence reduction under § 3582(c)(2) was properly denied). Mr. Norwood concedes that the guideline range would have remained the same based on the findings that the district court had made at sentencing. Appellant’s Opening Br. at 9. But Mr. Norwood challenges these\n",
            "Named entities: ['sentencing', '’s guideline', 'defendant', 'Br', 'reduction', 'Mr. Norwood concedes', 'findings', 'Opening', 'Mr.', 'Norwood', 'district', 'denied', 'guideline', '§', 'Appellant’s']\n",
            "Translations: ['判刑', '的指导方针', '被告', '溴', '减少', '诺伍德先生承认', '发现', '开场', '先生。', '诺伍德', '区', '否认', '指南', None, '上诉人的']\n",
            "\n",
            "Generated Response: 没有影响被告人的指导范围,根据§ 3582(c)(2)的规定,减刑被适当拒绝。 诺伍德先生承认,根据地区法院在量刑时做出的裁决,指导范围本应保持不变。 但诺伍德先生对此提出质疑。\n",
            "\n",
            "Generated Response: 不影响被告的指南范围,根据§ 3582(c)(2)不应减刑。\n",
            "\n",
            "Generated Response: 不影响被告的指导范围,根据§ 3582(c)(2)拒绝减刑是正确的。\n",
            "\n",
            "Generated Response (LEAP): 判刑的指导方针没有影响被告的范围, 根据§ 3582(c)(2) 减少判刑应被否认。诺伍德先生承认, 根据地区法院在判刑时做出的发现, 指南范围将保持不变。上诉人的开场陈述第9页。但是诺伍德先生对这些提出质疑。\n",
            "\n",
            "Generated Response (LEAP): 诺伍德先生承认, 根据法院在量刑时做出的裁定, 其判刑指导范围不会有变化。但诺伍德先生对此提出质疑。\n",
            "\n",
            "Generated Response (LEAP): 诺伍德先生承认,依据法院的裁决,被告的判刑幅度不会改变。诺伍德先生上诉称,法院正确地拒绝了根据§ 3582(c)(2) 的减刑。但诺伍德先生否认法院的裁决。\n",
            "Appended result to Google Drive file: ['law', 5, 0.20370370370370372, 0.537037037037037]\n",
            "Text 6: 887 (9th Cir.1991); United States v. Ramirez, 770 F.2d 1458, 1461 (9th Cir.1985); United States v. Manfredi, 722 F.2d 519, 522 (9th Cir.1983). Because dangerous people do not differentiate between misdemeanors and felonies, the law should not either. It is a fact that many officers are killed during traffic stops\n",
            "Named entities: ['Cir.1985', 'traffic', 'misdemeanors', 'law', 'United States v. Manfredi', 'United States v. Ramirez', 'killed', 'officers', 'stops', 'dangerous people', 'felonies']\n",
            "Translations: ['1985 年', '交通', '轻罪', '法律', '美国诉曼弗雷迪', '美国诉拉米雷斯', '被杀', '官员', '停止', '危险的人', '重罪']\n",
            "\n",
            "Generated Response: 887 (第9巡回区1991年); 美国诉拉米雷斯, 770 F.2d 1458, 1461 (第9巡回区1985年); 美国诉曼弗雷迪, 722 F.2d 519, 522 (第9巡回区1983年)。因为危险的人不区分轻罪和重罪,法律也不应该如此。事实是,许多警察在执行交通拦截时被杀。\n",
            "\n",
            "Generated Response: 887 (第九巡回区,1991年);美国对拉米雷斯,770 F.2d 1458,1461(第九巡回区,1985年);美国对曼夫雷迪,722 F.2d 519,522(第九巡回区,1983年)。因为危险人物不区分轻罪和重罪,法律也不应该如此。许多警官在交通检查期间遇害是一个事实。\n",
            "\n",
            "Generated Response: 887 (第9巡回法庭1991年); 美国对拉米雷斯案, 770 F.2d 1458, 1461 (第9巡回法庭1985年); 美国对曼弗雷迪案, 722 F.2d 519, 522 (第9巡回法庭1983年)。因为危险的人不会区分轻罪和重罪,所以法律也不应如此区分。许多警察在执行交通检查时被杀是事实。\n",
            "\n",
            "Generated Response (LEAP): 1985年、交通、轻罪、法律、美国诉曼弗雷迪、美国诉拉米雷斯、被杀、官员、停止、危险的人、重罪\n",
            "\n",
            "Generated Response (LEAP): 1985年 交通 轻罪 法律 美国诉曼弗雷迪 美国诉拉米雷斯 被杀 官员 停止 危险的人 重罪\n",
            "\n",
            "Generated Response (LEAP): 1985年,交通,轻罪,法律,美国诉曼弗雷迪,美国诉拉米雷斯,被杀,官员,停止,危险的人,重罪\n",
            "Appended result to Google Drive file: ['law', 6, 0.5454545454545454, 0.9090909090909091]\n",
            "Text 7: In essence, Landowners argue that Star Enterprise’s negligence has interfered with their ability to contract with third parties for the sale of their homes, the same type of damages, for which the Virginia Supreme Court imposed a physical impact requirement in Philip Morris. Landowners rely upon Pruitt v. Allied Chemical\n",
            "Named entities: ['interfered', 'Landowners', 'sale', 'Philip Morris', 'contract', 'parties', 'Virginia', 'essence', 'Star Enterprise’s negligence', 'Supreme', 'Court', 'physical impact', 'requirement', 'damages', 'homes']\n",
            "Translations: ['受到干扰', '土地所有者', '销售', '菲利普莫里斯', '合同', '各方', '弗吉尼亚州', '本质', '星空企业的疏忽', '最高', '法庭', '物理影响', '要求', '损害赔偿', '家']\n",
            "\n",
            "Generated Response: 沙漠企业的疏忽干扰了地主与第三方就销售房屋进行合同的能力,这种损害同样是维吉尼亚最高法院在菲利普莫里斯案件中要求有实际影响的情况。地主依赖普鲁伊特诉阿赖德化工公司一案。\n",
            "\n",
            "Generated Response: 地主\n",
            "\n",
            "Generated Response: 业主们主张斯达企业的疏忽干扰了他们与第三方就出售房屋订立合同的能力,这种损害与弗吉尼亚最高法院在菲利普-莫里斯案中规定的身体影响要求相同。业主依赖普鲁特诉阿德化学公司案。\n",
            "\n",
            "Generated Response (LEAP): 受到干扰\n",
            "土地所有者\n",
            "销售\n",
            "菲利普莫里斯\n",
            "合同\n",
            "各方\n",
            "弗吉尼亚州\n",
            "本质\n",
            "星空企业的疏忽\n",
            "最高\n",
            "法庭\n",
            "物理影响\n",
            "要求\n",
            "损害赔偿\n",
            "家\n",
            "\n",
            "Generated Response (LEAP): 受到干扰的土地所有者依据弗吉尼亚州最高法庭在菲利普莫里斯案中就类似损害要求物理影响的裁决,主张星空企业的疏忽影响了他们与第三方就出售房屋签订合同的能力,并请求获得损害赔偿。\n",
            "\n",
            "Generated Response (LEAP): 受到干扰的土地所有者要求销售他们的房屋并获得损害赔偿,这种类型的损害与弗吉尼亚州最高法院在菲利普莫里斯案中对物理影响的要求相同。土地所有者依赖普雷特诉联合化学公司案。\n",
            "Appended result to Google Drive file: ['law', 7, 0.16666666666666663, 0.7708333333333334]\n",
            "Text 8: Cas. and Sur. Co., 435 F.3d 252, 260 (3d Cir.2006) (“It has long been the rule in this Circuit that insurance policies are considered part of the property of a bankruptcy estate”) (citing Estate of Lellock v. The Prudential Ins. Co. of Am., 811 F.2d 186, 189 (3d Cir.1987)); In\n",
            "Named entities: ['Cas', 'bankruptcy estate', 'Am', 'policies', '3d Cir.2006', 'Prudential Ins', 'Sur', 'Lellock v.', 'property', 'Co.', 'insurance']\n",
            "Translations: ['卡斯', '破产财产', '是', '政策', '3d 环.2006', '保诚保险', '在', 'Lellock v.', '财产', '公司', '保险']\n",
            "\n",
            "Generated Response: 破产案中,保险单被视为资产的一部分。(In re Cas. and Sur. Co., 435 F.3d 252, 260 (3d Cir.2006); Estate of Lellock v. The Prudential Ins. Co. of Am., 811 F.2d 186, 189 (3d Cir.1987))\n",
            "\n",
            "Generated Response: 案件和诉讼公司，435 F.3d 252, 260 (3d Cir.2006)(\"本巡回区长期以来的规则是，保险单被视为破产财产的一部分\")(引用Estate of Lellock v. The Prudential Ins. Co. of Am., 811 F.2d 186, 189 (3d Cir.1987)); In\n",
            "\n",
            "Generated Response: 案. and 苏尔. 有限公司, 435 F.3d 252, 260 (第三巡回法院 2006) (\"在本巡回区,保险单被视为破产财产的一部分,这是一个长期存在的规则\") (引用 Estate of Lellock v. The Prudential Ins. Co. of Am., 811 F.2d 186, 189 (第三巡回法院 1987)); 在\n",
            "\n",
            "Generated Response (LEAP): 卡斯保险公司在破产财产中。\n",
            "\n",
            "Generated Response (LEAP): 卡斯保险公司，435 F.3d 252, 260 (3d 环.2006) (\"在这个巡回区域一直以来都有规定，保险单被视为破产财产的一部分\")(引用 Lellock v. 美国普信人寿保险公司, 811 F.2d 186, 189 (3d 环.1987)); 在\n",
            "\n",
            "Generated Response (LEAP): 卡斯公司保险在3d 环.2006政策中保诚保险是破产财产的一部分\n",
            "Appended result to Google Drive file: ['law', 8, 0.4722222222222222, 0.8055555555555556]\n",
            "Text 9: no evidence that Georgia’s “general” K-12 local schools offer “a year round program with multi-age, student-centered classrooms featuring pedagogy that is based on constructivist and multiple intelligence learning” like CCAT. Why is that curriculum not sufficiently different to qualify as “special”? Again, the majority does not say. If a “special\n",
            "Named entities: ['general” K-12', 'year', 'multi-age', 'student-centered classrooms', 'special', 'round program', 'pedagogy', 'curriculum', 'CCAT', 'Georgia']\n",
            "Translations: ['“普通” K-12', '年', '多种年龄', '以学生为中心的课堂', '特别的', '轮程序', '教育学', '课程', '加拿大癌症研究委员会', '乔治亚州']\n",
            "\n",
            "Generated Response: 没有证据表明格鲨的\"普通\"K-12 地方学校提供类似CCAT的\"全年制的多年级、以学生为中心的教室,采用基于建构主义和多元智能学习的教学法\"。为什么这种课程差异不足以被认定为\"特殊\"?同样,大多数人没有说明。如果一个\"特殊\"\n",
            "\n",
            "Generated Response: 没有证据表明乔治亚州的\"普通\"K-12 当地学校提供\"以学生为中心的全年制多年级课堂,其教学方法基于建构主义和多元智能学习理论\"等类似于CCAT的课程。为什么这种课程的差异不足以被归类为\"特殊\"?同样地,主体部分并没有解释这一点。如果一个\"特殊\"\n",
            "\n",
            "Generated Response: 无证据表明，乔治亚州的\"普通\"K-12地方学校提供\"全年计划,以多年级、以学生为中心的教室为特色,采用基于建构主义和多元智力学习的教学法\",就像CCAT一样。为什么该课程与\"特殊\"课程的差异不足以使其有资格获得\"特殊\"认定?同样,大多数人并未作出表述。如果\"特殊\"\n",
            "\n",
            "Generated Response (LEAP): 没有证据表明乔治亚州\"普通\" K-12 当地学校提供\"包含多种年龄、以学生为中心的课堂、基于建构主义和多元智能学习的教学法的全年课程\"，如加拿大癌症研究委员会。为什么该课程与\"特别的\"不够不同而无法满足资格要求?再次强调,大多数人并未说明。\n",
            "\n",
            "Generated Response (LEAP): 没有证据表明乔治亚州的\"普通\" K-12 地方学校提供\"以年为单位的多种年龄、以学生为中心的课堂,采用建构主义和多种智力学习教育学的特别程序\"像加拿大癌症研究委员会。为什么该课程与\"特别的\"课程没有足够的差异?大多数人没有说。如果一个\"特别的\n",
            "\n",
            "Generated Response (LEAP): 没有证据表明乔治亚州的\"普通\"K-12地方学校提供\"一年制多年龄、以学生为中心的教室,采用基于建构主义和多元智能学习的教学法\"像CCAT那样的课程。为什么该课程与\"特别的\"课程无法区分?同样,大多数人没有说明理由。\n",
            "Appended result to Google Drive file: ['law', 9, 0.3939393939393939, 0.8181818181818181]\n",
            "Text 10: that the “Florida Legislature created the Fund as a self-insurance fund to provide liability insurance to governmental agencies and employees in civil rights cases” (citing § 284.30, Fla. Stat.)). Section 284.30 provides that when a party seeks attorney’s fees from a state agency, the party is required to serve notice\n",
            "Named entities: ['liability', 'Fund', 'civil', 'employees', 'governmental agencies', 'state agency', 'party seeks', 'Florida Legislature', 'notice', 'self-insurance fund', '§', 'cases', 'Section', 'party']\n",
            "Translations: ['责任', '基金', '民事', '雇员', '政府机构', '国家机构', '政党寻求', '佛罗里达州立法机构', '注意', '自保基金', None, '案例', '部分', '派对']\n",
            "\n",
            "Generated Response: 这一条法律的原文: \"佛罗里达州立法机构设立了这一基金作为一个自我保险基金,为政府机构和公民权利案件中的员工提供责任保险\"(引用§ 284.30, Fla. Stat.))。第 284.30 条规定,当一方向州机构申请律师费时,该方必须先行通知。\n",
            "\n",
            "Generated Response: 佛罗里达州立法机构设立这一基金作为自我保险基金,为政府机构和员工在民权案件中提供责任保险(引用佛罗里达州法第284.30条)。284.30条规定,当一方向州机构寻求律师费时,该方必须提供通知。\n",
            "\n",
            "Generated Response: 这一条法律规定，佛罗里达州立法机构创建了该基金，作为一种自我保险基金，为政府机构和员工在民权案件中提供责任保险。 (引用 § 284.30, Fla. Stat.)) 第 284.30 节规定，当一方向州机构寻求律师费时，该方必须提供通知。\n",
            "\n",
            "Generated Response (LEAP): 佛罗里达州立法机构创建了这一自保基金，目的是为政府机构和民事案件中的雇员提供责任保险。根据佛罗里达州法284.30条款规定，当一方向国家机构寻求律师费时，该方须提供通知。\n",
            "\n",
            "Generated Response (LEAP): 佛罗里达州立法机构创建了基金作为自保基金,以向民事权利案件中的政府机构和雇员提供责任保险(引用佛罗里达州法令第284.30节)。第284.30节规定,当一方向国家机构寻求律师费时,该方被要求提供通知。\n",
            "\n",
            "Generated Response (LEAP): 责任基金\n",
            "Appended result to Google Drive file: ['law', 10, 0.4, 0.48888888888888893]\n",
            "Processing dataset: medical\n",
            "Text 1: This 60-year-old male was hospitalized due to moderate ARDS from COVID-19 with symptoms of fever, dry cough, and dyspnea. We encountered several difficulties during physical therapy on the acute ward. First, any change of position or deep breathing triggered coughing attacks that induced oxygen desaturation and dyspnea. To avoid rapid\n",
            "Named entities: ['deep breathing', 'male', 'COVID-19', 'fever', 'ARDS', 'position', 'difficulties', 'induced', 'dyspnea', 'acute ward', 'dry cough', 'symptoms', 'moderate', 'oxygen desaturation', 'hospitalized', 'physical therapy']\n",
            "Translations: ['深呼吸', '男性', '新冠肺炎', '发烧', 'ARDS', '位置', '困难', '诱导', '呼吸困难', '急症病房', '干咳', '症状', '缓和', '氧饱和度降低', '住院', '物理治疗']\n",
            "\n",
            "Generated Response: 这名60岁男性因新冠肺炎引发的中度急性呼吸窘迫综合征住院,症状包括发烧、干咳和呼吸困难。在急诊科进行物理治疗时遇到了一些困难。首先,任何体位变化或深呼吸都会引发剧烈咳嗽,导致血氧饱和度下降和呼吸困难。为了避免迅速\n",
            "\n",
            "Generated Response: 这位60岁的男性患者由于2019冠状病毒病感染而出现中度急性呼吸窘迫综合征(ARDS),出现发烧、干咳和呼吸困难等症状。在急诊病房进行物理治疗时,我们遇到了几个困难:首先,任何体位变化或深呼吸都会引发剧烈的咳嗽发作,导致血氧饱和度下降和呼吸困难。为避免快速\n",
            "\n",
            "Generated Response: 这位60岁男性因新冠肺炎引发中度急性呼吸窘迫综合征而住院,症状包括发烧、干咳和呼吸困难。在急诊病房进行的物理治疗过程中,我们遇到了几个困难。首先,任何体位变化或深呼吸都会引发咳嗽发作,导致氧饱和度下降和呼吸困难。为了避免快\n",
            "\n",
            "Generated Response (LEAP): 这名60岁男性由于新冠肺炎引起的中度ARDS而住院,症状包括发烧、干咳和呼吸困难。我们在急症病房进行物理治疗时遇到了一些困难。首先,任何改变体位或进行深呼吸都会引发咳嗽发作,导致氧饱和度降低和呼吸困难。为了避免急\n",
            "\n",
            "Generated Response (LEAP): 这60岁男性因新冠肺炎引起的中度ARDS而住院,症状包括发烧、干咳和呼吸困难。在急症病房里进行物理治疗时,我们遇到了一些困难。首先,任何改变姿势或深呼吸都会引发咳嗽发作,导致氧饱和度降低和呼吸困难。为了避免急速\n",
            "\n",
            "Generated Response (LEAP): 这名60岁的男性由于新冠肺炎引发中度ARDS而住院,症状包括发烧、干咳和呼吸困难。我们在急症病房进行物理治疗时遇到了几个困难。首先,任何位置变化或深呼吸都会引发剧烈咳嗽,导致氧饱和度降低和呼吸困难。为了避免急剧\n",
            "Appended result to Google Drive file: ['medical', 1, 0.7450980392156863, 0.9607843137254902]\n",
            "Text 2: A 39-year-old man was hospitalized due to an increasingly reduced general health condition, after persistent fever and dry cough for 2 weeks. The patient initially needed 4 L/min of oxygen, had a rapid and shallow breathing pattern at rest and became severely breathless during minor physical activities. In the beginning,\n",
            "Named entities: ['general health condition', 'physical activities', 'fever', 'breathless', 'persistent', 'rest', 'patient', 'weeks', 'dry cough', 'oxygen', 'minor', 'L/min of', 'increasingly', 'man', 'beginning', 'hospitalized']\n",
            "Translations: ['总体健康状况', '体力活動', '发烧', '喘不过气来', '执着的', '休息', '病人', '周', '干咳', '氧', '次要的', '升/分钟', '日益', '男人', '开始', '住院']\n",
            "\n",
            "Generated Response: 39岁男性由于持续2周的发烧和干咳导致总体健康状况恶化,而被送入医院。该患者初期需要4升/分钟的氧气,在休息状态下呼吸快速且浅。在进行轻微体力活动时也会严重喘息。\n",
            "\n",
            "Generated Response: 一个39岁男性因全身健康状况持续恶化而住院,持续2周的发烧和干咳。患者最初需要4升/分钟的氧气,休息时呼吸急促浅表,进行轻微体力活动时严重呼吸困难。\n",
            "\n",
            "Generated Response: 一位39岁男性由于持续2周的发烧和干咳导致全身健康状况明显下降而入院。患者最初需要氧气4升/分钟,休息时呼吸急促且浅,在轻微运动时严重呼吸困难。\n",
            "\n",
            "Generated Response (LEAP): 39岁男性由于总体健康状况日益下降,在持续发烧和干咳2周后被送入医院。该病人最初需要4升/分钟的氧气,在休息时呼吸急促且浅表,在进行轻微体力活动时严重喘不过气来。开始时,\n",
            "\n",
            "Generated Response (LEAP): 39岁男性因全身健康状况日益恶化,持续两周发烧和干咳而住院。病人最初需要4升/分钟的氧气,在休息时呼吸急促而浅表,在轻微体力活动时严重呼吸困难。\n",
            "\n",
            "Generated Response (LEAP): 一名39岁的男性患者因总体健康状况日益恶化,经2周持续发烧和干咳而被送往医院。病人最初需要每分钟4升的氧气,在休息时呼吸急促且浅表,在做轻微体力活动时严重喘不过气来。开始时,\n",
            "Appended result to Google Drive file: ['medical', 2, 0.41666666666666663, 0.625]\n",
            "Text 3: One week after a positive COVID-19 result this 57-year-old male was admitted to the ICU because of oxygen desaturation (70%) with worsening tachypnea and dyspnea. Physical therapy started immediately after ICU admission. We found a highly dyspneic patient with a high breathing frequency and significant symptom exacerbation from the slightest\n",
            "Named entities: ['male', 'COVID-19', 'dyspneic', 'significant', 'ICU', 'breathing frequency', 'positive', 'admitted', 'tachypnea', 'dyspnea', 'Physical therapy', 'patient', 'symptom exacerbation', 'week', 'worsening', 'started', 'oxygen desaturation', 'ICU admission']\n",
            "Translations: ['男性', '新冠肺炎', '呼吸困难', '重要的', '重症监护室', '呼吸频率', '积极的', '承认', '呼吸急促', '呼吸困难', '物理治疗', '病人', '症状加重', '星期', '恶化', '开始', '氧饱和度降低', 'ICU入院']\n",
            "\n",
            "Generated Response: 这位57岁男性在新冠肺炎检测呈阳性后一周,因氧饱和度下降(70%)、呼吸急促和呼吸困难恶化而被收治进入重症监护室。他在入院重症监护室后立即开始进行Physical therapy。我们发现这名患者呼吸非常急促,呼吸频率高,即使稍有活动就会明显恶化症状。\n",
            "\n",
            "Generated Response: 一周后，这名57岁男性因氧饱和度下降(70%)、呼吸急促和呼吸困难而被送入 ICU。他在 ICU 入院后立即开始物理治疗。我们发现这名患者非常呼吸困难,呼吸频率高,只要稍有活动就会明显加重症状。\n",
            "\n",
            "Generated Response: 一周后,这名57岁男性在COVID-19检测呈阳性后由于氧饱和度下降(70%)、呼吸急促和呼吸困难加重而入住ICU。ICU入院后立即开始物理治疗。我们发现该患者呼吸非常急促,呼吸频率很高,且即使稍有活动就会症状严重加重。\n",
            "\n",
            "Generated Response (LEAP): 57岁男性确诊新冠肺炎一周后,因氧饱和度下降(70%)、呼吸急促和呼吸困难加重而入ICU。入ICU后立即开始物理治疗。我们发现该患者呼吸非常困难,呼吸频率高,即使稍有活动也会症状加重。\n",
            "\n",
            "Generated Response (LEAP): 一个星期后,这位57岁的男性新冠阳性检测结果,因氧饱和度下降(70%)、呼吸频率加快和呼吸困难而被送入重症监护室。物理治疗立即开始。我们发现这位病人呼吸非常困难,呼吸频率很高,即使稍微动一下症状也会明显恶化。\n",
            "\n",
            "Generated Response (LEAP): 一个阳性新冠肺炎结果后一个星期,这个57岁的男性因氧饱和度下降(70%)、呼吸急促和呼吸困难加重而被收入重症监护室。物理治疗在重症监护室入院后立即开始。我们发现这位病人呼吸困难严重,呼吸频率高,且最小的活动都会导致症状严重恶化。\n",
            "Appended result to Google Drive file: ['medical', 3, 0.49122807017543857, 0.6140350877192983]\n",
            "Text 4: This 69-year-old male was admitted to the ICU after a dry cough for 2 weeks, oxygenation was poor and computer tomographic imaging showed typical COVID-19 pneumonia. Initially the patient received lung-protective ventilation and targeted sedation, but was otherwise stable. Treatment interventions included passive range of motion and positioning including passive\n",
            "Named entities: ['male', 'COVID-19', 'computer tomographic imaging', 'lung-protective ventilation', 'targeted', 'passive', 'ICU', 'oxygenation', 'sedation', 'admitted', 'patient', 'weeks', 'dry cough', 'Treatment interventions', 'stable', 'pneumonia', 'poor']\n",
            "Translations: ['男性', '新冠肺炎', '电脑断层扫描成像', '肺保护性通气', '有针对性的', '被动的', '重症监护室', '氧合', '镇静', '承认', '病人', '周', '干咳', '治疗干预', '稳定的', '肺炎', '贫穷的']\n",
            "\n",
            "Generated Response: 这69岁的男性在干咳持续2周后被送入ICU,氧合能力较差,CT成像显示典型的新冠肺炎。起初,患者接受了保肺通气及目标性镇静,但其他情况较为稳定。治疗措施包括被动关节活动和体位调整。\n",
            "\n",
            "Generated Response: 这位69岁的男性在出现干咳2周后被送入重症监护室,氧合能力较差,电脑断层扫描显示典型的新冠肺炎。患者最初接受了肺部保护性通气和针对性镇静,但其他情况稳定。治疗措施包括被动关节活动范围训练和体位调整,包括被动\n",
            "\n",
            "Generated Response: 这69岁男性在干咳2周后被收治入 ICU,氧合不佳,电脑断层扫描显示典型的 COVID-19 肺炎。最初患者接受了肺部保护通气和针对性镇静,但其他稳定。治疗措施包括被动关节活动和体位调整。\n",
            "\n",
            "Generated Response (LEAP): 这位69岁的男性在干咳2周后被收入重症监护室,氧合不良,电脑断层扫描成像显示典型的新冠肺炎。最初病人接受了肺保护性通气和有针对性的镇静,但总体状况稳定。治疗干预包括被动的关节活动和体位调整。\n",
            "\n",
            "Generated Response (LEAP): 这位69岁的男性在干咳2周后被送入重症监护室,氧合不良,电脑断层扫描成像显示典型的新冠肺炎。最初,患者接受了肺保护性通气和针对性的镇静,但其他方面保持稳定。治疗干预包括被动的关节活动和体位调整。\n",
            "\n",
            "Generated Response (LEAP): 这位69岁男性在咳嗽2周后被送入重症监护室,氧合情况不佳,电脑断层扫描成像显示典型的新冠肺炎。最初,病人接受了肺保护性通气和有针对性的镇静,但其他方面保持稳定。治疗干预措施包括被动的关节活动和体位调整。\n",
            "Appended result to Google Drive file: ['medical', 4, 0.38888888888888884, 0.7222222222222222]\n",
            "Text 5: This 57-year-old male was admitted to the ICU with dyspnea, heavy dry cough, and fever 6 days after testing positive for COVID-19. Initially, he was able to exercise and sit in a chair with a physical therapist, but progressive respiratory failure necessitated intubation and proning. The patient had large amounts\n",
            "Named entities: ['COVID-19', 'testing', 'days', 'fever', 'progressive', 'exercise', 'admitted', 'proning', 'chair', 'positive', 'dyspnea', 'male', 'necessitated intubation', 'ICU', 'patient', 'physical therapist', 'heavy dry cough', 'respiratory failure', 'sit']\n",
            "Translations: ['新冠肺炎', '测试', '天', '发烧', '进步', '锻炼', '承认', '俯卧', '椅子', '积极的', '呼吸困难', '男性', '需要插管', '重症监护室', '病人', '物理治疗师', '严重干咳', '呼吸衰竭', '坐']\n",
            "\n",
            "Generated Response: 这位57岁的男性在检测呈阳性6天后被送入ICU,出现呼吸困难、严重的干咳和发烧。起初他能进行锻炼并在物理治疗师的帮助下坐在椅子上,但呼吸衰竭逐渐加重,需要进行气管插管和俯卧位治疗。这名患者出现大量\n",
            "\n",
            "Generated Response: 这名57岁男性在COVID-19检测呈阳性6天后被收治进入重症监护室,症状为呼吸困难、重干咳和发烧。起初他能进行锻炼并在物理治疗师的帮助下坐在椅子上,但随后出现呼吸衰竭加重,需进行气管插管和俯卧位治疗。该患者出现大量痰液分泌。\n",
            "\n",
            "Generated Response: 这位57岁的男性在新冠肺炎检测呈阳性6天后被送入重症监护室,症状包括呼吸困难、剧烈干咳和发烧。最初他还能够锻炼并坐在椅子上进行物理治疗,但症状进行性恶化,最终需要插管和趴伏治疗。患者肺部出现大量\n",
            "\n",
            "Generated Response (LEAP): 这位57岁男性在新冠肺炎检测呈阳性6天后,因呼吸困难、严重干咳和发烧而入住重症监护室。最初他能够进行锻炼和与物理治疗师一起坐在椅子上,但逐渐出现呼吸衰竭,需要插管和俯卧。病人出现大量\n",
            "\n",
            "Generated Response (LEAP): 这位57岁的男性在新冠肺炎检测呈阳性6天后,因呼吸困难、严重干咳和发烧而被收入重症监护室。开始他还能锻炼和坐在椅子上进行物理治疗,但呼吸衰竭逐步加重,需要进行插管和俯卧。这名病人出现大量\n",
            "\n",
            "Generated Response (LEAP): 这位57岁的男性在新冠肺炎检测呈阳性6天后被送入重症监护室,症状包括呼吸困难、严重干咳和发烧。最初他能够进行锻炼和在物理治疗师的协助下坐在椅子上,但后来呼吸衰竭加重,需要插管和采取俯卧位。病人呼吸严重受损。\n",
            "Appended result to Google Drive file: ['medical', 5, 0.4920634920634921, 0.6825396825396826]\n",
            "Text 6: This 52-year-old male tested COVID-19 positive 4 days after the beginning of a dry cough, fever, and head and limb pain. One day later, he was hospitalized with exertional dyspnea. He was diagnosed with pneumonia that developed into moderate ARDS needing mechanical ventilation and intermittent dialysis. After extubation, oxygenation was\n",
            "Named entities: ['COVID-19', 'exertional dyspnea', 'pneumonia', 'days', 'limb pain', 'fever', 'day', 'dry cough', 'extubation', 'intermittent dialysis', 'hospitalized', 'mechanical ventilation', 'tested', 'positive', 'male', 'ARDS', 'oxygenation', 'diagnosed', 'moderate', 'head']\n",
            "Translations: ['新冠肺炎', '劳力性呼吸困难', '肺炎', '天', '肢体疼痛', '发烧', '天', '干咳', '拔管', '间歇性透析', '住院', '机械通气', '已测试', '积极的', '男性', 'ARDS', '氧合', '诊断', '缓和', '头']\n",
            "\n",
            "Generated Response: 这名52岁男性在出现干咳、发烧和头痛及肢体疼痛4天后检测新冠病毒呈阳性。次日其被送入医院,因活动后出现呼吸困难。诊断为肺炎并发展成中度急性呼吸窘迫综合征,需要机械通气和间歇性透析治疗。拔除气管插管后,氧合情况\n",
            "\n",
            "Generated Response: 这位52岁男性在干咳、发烧和头痛以及四肢疼痛开始4天后检测COVID-19呈阳性。一天后,他因运动性呼吸困难被送入医院。他被诊断为肺炎,后发展为中度急性呼吸窘迫综合征,需要机械通气和间歇性透析。拔除气管插管后,氧合情况\n",
            "\n",
            "Generated Response: 这位52岁的男性在干咳、发烧和头痛腿痛开始后的4天内检测出COVID-19阳性。一天后,他因运动性呼吸困难被送往医院。他被诊断为肺炎并发展为中度ARDS,需要机械通气和间歇性透析。拔除气管插管后,氧合情况\n",
            "\n",
            "Generated Response (LEAP): 这 52 岁男性在出现干咳、发烧和头痛、肢体疼痛开始 4 天后检测为新冠肺炎阳性。一天后,他因劳力性呼吸困难而住院。他被诊断为肺炎,并发展为中度 ARDS,需要机械通气和间歇性透析。拔管后,他的氧合状况\n",
            "\n",
            "Generated Response (LEAP): 这名52岁男性在出现干咳、发烧和头疼、肢体疼痛4天后检测新冠肺炎呈阳性。一天后入院，出现劳力性呼吸困难。诊断为肺炎,进而发展为中度ARDS,需要机械通气和间歇性透析。拔管后,氧合状况\n",
            "\n",
            "Generated Response (LEAP): 这位52岁的男性在开始出现干咳、发烧和头部及肢体疼痛4天后检测出新冠肺炎呈阳性。一天后，他因劳力性呼吸困难住院。他被诊断为肺炎，进而发展为中度ARDS，需要机械通气和间歇性透析。拔管后，氧合\n",
            "Appended result to Google Drive file: ['medical', 6, 0.6190476190476191, 0.9365079365079365]\n",
            "Text 7: Paramedics found this 59-year-old female with dyspnea and an oxygenation of 65% on room air and performed immediate tracheal intubation. Moderate ARDS with reduced lung compliance was diagnosed and treated with deep sedation, neuromuscular blocking agents, and prone positioning.\\nOn day 14, a trial of sitting on the edge-of-bed (SOEB) was\n",
            "Named entities: ['tracheal', 'deep sedation', 'trial', 'female', 'Moderate', 'neuromuscular blocking agents', 'treated with', 'reduced', 'compliance', 'intubation', 'dyspnea', 'prone', 'room air', 'Paramedics', 'sitting', 'ARDS', 'oxygenation', 'diagnosed', 'edge-of-bed (SOEB', 'lung']\n",
            "Translations: ['气管', '深度镇静', '审判', '女性', '缓和', '神经肌肉阻断剂', '治疗', '减少', '遵守', '插管', '呼吸困难', '易于', '室内空气', '医护人员', '坐', 'ARDS', '氧合', '诊断', '床边（SOEB', '肺']\n",
            "\n",
            "Generated Response: 急救人员发现这名59岁女性呼吸困难,室温空气氧合率为65%,立即进行气管插管。诊断为中度急性呼吸窘迫综合征,肺顺应性减低,采取深度镇静、神经肌肉松弛药物及俯卧位治疗。\n",
            "\n",
            "第14天,开始尝试床边坐位。\n",
            "\n",
            "Generated Response: 急救人员发现这名59岁女性出现呼吸困难,室内空气氧合率为65%,立即进行了气管插管。诊断为中度ARDS,伴有肺顺应性下降,予以深度镇静、神经肌肉阻滞剂和俯卧位治疗。\n",
            "\n",
            "第14天开始尝试坐在床沿(SOEB)。\n",
            "\n",
            "Generated Response: 急救人员发现这位59岁的女性有呼吸困难,室内空气氧化水平为65%,立即进行了气管插管。诊断为中度急性呼吸窘迫综合症,肺顺应性降低,采取深度镇静、神经肌肉阻滞剂和俯卧位的治疗方法。\n",
            "\n",
            "在第14天,尝试了坐在床沿上的康复训练。\n",
            "\n",
            "Generated Response (LEAP): 气管插管、深度镇静、神经肌肉阻断剂、减少、遵守、呼吸困难、室内空气、医护人员、坐、ARDS、氧合、诊断、床边（SOEB）、肺。\n",
            "\n",
            "Generated Response (LEAP): 气管插管, 深度镇静, 审判, 女性, 缓和, 神经肌肉阻断剂, 治疗, 减少, 遵守, 插管, 呼吸困难, 易于, 室内空气, 医护人员, 坐, ARDS, 氧合, 诊断, 床边（SOEB), 肺\n",
            "\n",
            "Generated Response (LEAP): 气管插管，呼吸困难，氧合降低，诊断为中度ARDS并伴有肺顺应性降低。采取深度镇静、神经肌肉阻断剂及趴卧治疗。\n",
            "\n",
            "第14天尝试床边坐位（SOEB）。\n",
            "Appended result to Google Drive file: ['medical', 7, 0.5333333333333333, 0.7833333333333333]\n",
            "Text 8: This 33-year-old female patient had typical COVID-19 symptoms such as high fever, dry cough, headache, and dyspnea about 1 week before ICU admission. She was intubated and proned due to rapid respiratory deterioration. For the following 6 days, her situation was unstable, and physical therapy consisted of prone positioning and\n",
            "Named entities: ['COVID-19', 'female', 'situation', 'respiratory deterioration', 'dyspnea', 'headache', 'patient', 'unstable', 'dry cough', 'prone', 'symptoms', 'proned', 'week', 'intubated', 'high fever', 'ICU admission', 'days', 'physical therapy']\n",
            "Translations: ['新冠肺炎', '女性', '情况', '呼吸功能恶化', '呼吸困难', '头痛', '病人', '不稳定', '干咳', '易于', '症状', '俯卧', '星期', '插管', '高烧', 'ICU入院', '天', '物理治疗']\n",
            "\n",
            "Generated Response: 这位33岁的女性患者在入住ICU前大约1周出现了典型的COVID-19症状,如高烧、干咳、头痛和呼吸困难。由于呼吸恶化迅速,她被插管并采取俯卧位治疗。在接下来的6天内,她的情况一直很不稳定,物理治疗包括俯卧位及\n",
            "\n",
            "Generated Response: 这33岁的女性患者在入住ICU前约1周出现典型的COVID-19症状,如高烧、干咳、头痛和呼吸困难。由于呼吸迅速恶化,她被插管并采取俯卧位。在随后的6天里,她的情况不稳定,物理治疗包括采取俯卧位。\n",
            "\n",
            "Generated Response: 这位33岁的女性患者在重症监护室入院前大约1周出现了典型的COVID-19症状,如高烧、干咳、头痛和呼吸困难。由于呼吸迅速恶化,她被插管并采取俯卧位治疗。在接下来的6天里,她的情况一直不稳定,物理治疗包括采取俯卧位。\n",
            "\n",
            "Generated Response (LEAP): 这 33 岁的女性患者在 ICU 入院前大约 1 周出现典型的新冠肺炎症状,如高烧、干咳、头痛和呼吸困难。由于呼吸功能急剧恶化,她被插管并采取了俯卧姿势治疗。在接下来的 6 天里,她的情况一直不稳定,接受了物理治疗,包括采取俯卧姿势和\n",
            "\n",
            "Generated Response (LEAP): 这33岁的女性病人在进入ICU前约1周出现了典型的新冠肺炎症状,如高烧、干咳、头痛和呼吸困难。由于呼吸功能急剧恶化,她被插管并采取了俯卧位治疗。在接下来的6天里,她的情况一直不稳定,进行了俯卧位治疗和物理治疗。\n",
            "\n",
            "Generated Response (LEAP): 这位 33 岁的女性病人在 ICU 入院前约 1 周出现典型的 新冠肺炎 症状,如 高烧、干咳、头痛和 呼吸困难。由于 呼吸功能恶化迅速,她被插管并进行了 俯卧。在接下来的 6 星期里,她的情况一直 不稳定,物理治疗包括 俯卧位和其他治疗。\n",
            "Appended result to Google Drive file: ['medical', 8, 0.6842105263157895, 0.7894736842105263]\n",
            "Text 9: This 66-year-old male patient was admitted to the hospital due to an ischemic left-hemispheric stroke in addition to a dry cough and fever. He tested positive for SARS-CoV-2 the following day but continued to deteriorate resulting in severe ARDS, intubation, and ICU admission. Despite repeated proning, gas exchange did not\n",
            "Named entities: ['male', 'fever', 'day', 'ARDS', 'admitted to', 'ischemic', 'positive', 'deteriorate', 'intubation', 'patient', 'dry cough', 'severe', 'proning', 'left-hemispheric stroke', 'SARS-CoV-2', 'gas exchange', 'ICU admission', 'hospital']\n",
            "Translations: ['男性', '发烧', '天', 'ARDS', '承认', '缺血', '积极的', '恶化', '插管', '病人', '干咳', '严重', '俯卧', '左半球卒中', 'SARS-CoV-2', '气体交换', 'ICU入院', '医院']\n",
            "\n",
            "Generated Response: 这名66岁的男性患者因缺血性左半球中风以及干咳和发烧而入院。次日其新冠病毒检测呈阳性,但病情恶化导致严重急性呼吸窘迫综合征、需要气管插管和入住重症监护室。尽管反复进行俯卧位治疗,但气体交换仍未得到改善。\n",
            "\n",
            "Generated Response: 这位 66 岁的男性患者因左半球缺血性中风,并出现干咳和发烧,入院治疗。次日检出 SARS-CoV-2 阳性,病情持续恶化,出现严重急性呼吸窘迫综合征,需要气管插管和入住重症监护室。尽管多次采取腹卧位治疗,但气体交换状况仍未改善。\n",
            "\n",
            "Generated Response: 这66岁男性患者因伊斯兰教的左半球中风,并出现干咳和发烧而入院。次日检测呈SARS-CoV-2阳性,但其病情恶化,导致重症急性呼吸窘迫综合征、需要插管和入住重症监护病房。尽管多次采取俯卧位,但气体交换仍然未能改善。\n",
            "\n",
            "Generated Response (LEAP): 这66岁的男性病人因左半球缺血性卒中以及干咳和发烧而入院。次日检测呈SARS-CoV-2阳性,但病情持续恶化导致严重ARDS,需要插管治疗并入住ICU。尽管多次采取俯卧体位,但气体交换并未\n",
            "\n",
            "Generated Response (LEAP): 这66岁男性病人因缺血性左半球卒中以及干咳和发烧而入院。次日检测SARS-CoV-2呈阳性,但病情继续恶化,导致严重ARDS、插管和ICU入院。尽管多次采取俯卧位,但气体交换仍未改善。\n",
            "\n",
            "Generated Response (LEAP): 这位66岁的男性患者因缺血性左半球卒中以及干咳和发烧而入院。次日确诊为SARS-CoV-2阳性,但病情持续恶化,导致严重ARDS、插管和ICU入院。尽管多次采取俯卧位,但气体交换情况没有改善。\n",
            "Appended result to Google Drive file: ['medical', 9, 0.4814814814814815, 0.7222222222222222]\n",
            "Text 10: A 66-year-old male started to present symptoms of fever, dyspnea, coughing, asthenia, lack of appetite, nausea, and vomiting. He was admitted to the acute care unit for observation and oxygen therapy, but his oxygen requirements constantly increased due to moderate ARDS. After 12 days of deep sedation, neuromuscular blocking agents,\n",
            "Named entities: ['coughing', 'vomiting', 'nausea', 'deep sedation', 'acute care unit', 'days', 'oxygen requirements', 'fever', 'neuromuscular blocking agents', 'admitted', 'observation', 'dyspnea', 'symptoms', 'male', 'lack of appetite', 'oxygen therapy', 'ARDS', 'asthenia', 'increased', 'moderate']\n",
            "Translations: ['咳嗽', '呕吐', '恶心', '深度镇静', '急症护理病房', '天', '氧气需求量', '发烧', '神经肌肉阻断剂', '承认', '观察', '呼吸困难', '症状', '男性', '食欲不振', '氧气治疗', 'ARDS', '乏力', '增加', '缓和']\n",
            "\n",
            "Generated Response: 一位66岁的男性开始出现发热、呼吸困难、咳嗽、乏力、食欲不振、恶心和呕吐等症状。他被收入急诊监护病房接受观察和氧气疗法,但由于中度急性呼吸窘迫综合征,他的氧气需求不断增加。经过12天的深度镇静、神经肌肉阻滞剂治疗后,\n",
            "\n",
            "Generated Response: 一个66岁的男性开始出现发烧、呼吸困难、咳嗽、乏力、食欲不振、恶心和呕吐的症状。他被收入急诊护理单元进行观察和氧疗,但由于中度ARDS他的氧气需求不断增加。在经过12天的深度镇静、神经肌肉阻滞剂治疗后,\n",
            "\n",
            "Generated Response: 一位66岁男性开始出现发烧、呼吸困难、咳嗽、乏力、食欲不振、恶心和呕吐的症状。他被收治到急诊观察及供氧治疗病房,但由于中度急性呼吸窘迫综合征,他对氧气的需求不断增加。经过12天的深度镇静和神经肌肉阻滞剂治疗后,\n",
            "\n",
            "Generated Response (LEAP): 66岁男性出现发烧、呼吸困难、咳嗽、乏力、食欲不振、恶心和呕吐症状。他被收入急症护理病房进行观察和氧气治疗,但由于中度ARDS,他的氧气需求量不断增加。经过12天的深度镇静和神经肌肉阻断剂治疗后,\n",
            "\n",
            "Generated Response (LEAP): 66岁男性开始出现发烧、呼吸困难、咳嗽、乏力、食欲不振、恶心和呕吐的症状。他被收入急症护理病房进行观察和氧气治疗,但因中度ARDS导致氧气需求量不断增加。经过12天的深度镇静和神经肌肉阻断剂治疗,\n",
            "\n",
            "Generated Response (LEAP): 66 岁男性开始出现发烧、呼吸困难、咳嗽、乏力、食欲不振、恶心和呕吐等症状。他被收入急症护理病房进行观察和氧气治疗,但由于中度 ARDS 其氧气需求量不断增加。经过 12 天的深度镇静和神经肌肉阻断剂治疗后,\n",
            "Appended result to Google Drive file: ['medical', 10, 0.65, 0.9]\n"
          ]
        }
      ]
    }
  ]
}